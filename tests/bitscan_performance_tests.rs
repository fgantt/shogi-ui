//! Performance regression tests for bit-scanning optimization system
//! 
//! These tests ensure that the bit-scanning optimizations meet performance
//! targets and don't regress over time.

use shogi_engine::bitboards::{
    // Platform detection
    get_platform_capabilities, get_best_popcount_impl, get_best_bitscan_impl,
    // Popcount functions
    popcount, popcount_optimized, is_single_bit, is_multiple_bits, is_empty,
    // Bit scanning functions
    bit_scan_forward, bit_scan_reverse, clear_lsb, clear_msb, 
    isolate_lsb, isolate_msb, get_all_bit_positions, bit_scan_optimized,
    // Implementation-specific functions
    popcount::{
        popcount_hardware, popcount_bit_parallel, popcount_software,
    },
    bitscan::{
        bit_scan_forward_hardware, bit_scan_forward_debruijn, bit_scan_forward_software,
        bit_scan_reverse_hardware, bit_scan_reverse_debruijn, bit_scan_reverse_software,
    },
};
use shogi_engine::types::Bitboard;
use std::time::{Duration, Instant};

/// Performance benchmarks for popcount operations
#[test]
fn test_popcount_performance_benchmarks() {
    let test_cases = [
        ("Empty", 0u128),
        ("Single bit", 1u128),
        ("Sparse", 0x1000000000000000u128),
        ("Dense", 0xFFFFFFFFFFFFFFFFu128),
        ("Pattern", 0x5555555555555555u128),
        ("Random", 0x123456789ABCDEF0u128),
        ("Full 128-bit", 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFu128),
    ];
    
    let iterations = 1_000_000;
    
    for (name, bb) in test_cases {
        println!("\n=== Popcount Performance: {} ===", name);
        
        // Benchmark hardware implementation
        #[cfg(all(target_arch = "x86_64", not(target_arch = "wasm32")))]
        {
            let start = Instant::now();
            for _ in 0..iterations {
                let _result = popcount_hardware(bb);
            }
            let hardware_duration = start.elapsed();
            let avg_ns = hardware_duration.as_nanos() / iterations;
            println!("  Hardware: {:?} total, {}ns per call", hardware_duration, avg_ns);
            
            // Verify performance target: < 5 CPU cycles (roughly < 20ns on modern CPU)
            assert!(avg_ns < 50, "Hardware popcount too slow: {}ns per call", avg_ns);
        }
        
        // Benchmark SWAR implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = popcount_bit_parallel(bb);
        }
        let swar_duration = start.elapsed();
        let avg_ns = swar_duration.as_nanos() / iterations;
        println!("  SWAR: {:?} total, {}ns per call", swar_duration, avg_ns);
        
        // Verify performance target: 3-5x faster than software
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = popcount_software(bb);
        }
        let software_duration = start.elapsed();
        let software_avg_ns = software_duration.as_nanos() / iterations;
        println!("  Software: {:?} total, {}ns per call", software_duration, software_avg_ns);
        
        // SWAR should be faster than software
        assert!(swar_duration <= software_duration, 
                "SWAR implementation should be faster than software");
        
        // Benchmark optimized implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = popcount_optimized(bb);
        }
        let optimized_duration = start.elapsed();
        let optimized_avg_ns = optimized_duration.as_nanos() / iterations;
        println!("  Optimized: {:?} total, {}ns per call", optimized_duration, optimized_avg_ns);
        
        // Optimized should be at least as fast as the best implementation
        assert!(optimized_duration <= swar_duration,
                "Optimized implementation should be at least as fast as SWAR");
    }
}

/// Performance benchmarks for bit scanning operations
#[test]
fn test_bitscan_performance_benchmarks() {
    let test_cases = [
        ("Empty", 0u128),
        ("Single bit", 1u128),
        ("Sparse", 0x1000000000000000u128),
        ("Dense", 0xFFFFFFFFFFFFFFFFu128),
        ("Pattern", 0xAAAAAAAAAAAAAAAAu128),
        ("Random", 0x123456789ABCDEF0u128),
        ("Full 128-bit", 0xFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFFu128),
    ];
    
    let iterations = 1_000_000;
    
    for (name, bb) in test_cases {
        println!("\n=== Bit Scan Forward Performance: {} ===", name);
        
        // Benchmark hardware implementation
        #[cfg(all(target_arch = "x86_64", not(target_arch = "wasm32")))]
        {
            let start = Instant::now();
            for _ in 0..iterations {
                let _result = bit_scan_forward_hardware(bb);
            }
            let hardware_duration = start.elapsed();
            let avg_ns = hardware_duration.as_nanos() / iterations;
            println!("  Hardware: {:?} total, {}ns per call", hardware_duration, avg_ns);
            
            // Verify performance target: < 10 CPU cycles (roughly < 40ns on modern CPU)
            assert!(avg_ns < 100, "Hardware bitscan too slow: {}ns per call", avg_ns);
        }
        
        // Benchmark DeBruijn implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_forward_debruijn(bb);
        }
        let debruijn_duration = start.elapsed();
        let avg_ns = debruijn_duration.as_nanos() / iterations;
        println!("  DeBruijn: {:?} total, {}ns per call", debruijn_duration, avg_ns);
        
        // Benchmark software implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_forward_software(bb);
        }
        let software_duration = start.elapsed();
        let software_avg_ns = software_duration.as_nanos() / iterations;
        println!("  Software: {:?} total, {}ns per call", software_duration, software_avg_ns);
        
        // DeBruijn should be faster than software
        assert!(debruijn_duration <= software_duration,
                "DeBruijn implementation should be faster than software");
        
        // Benchmark optimized implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_optimized(bb, true);
        }
        let optimized_duration = start.elapsed();
        let optimized_avg_ns = optimized_duration.as_nanos() / iterations;
        println!("  Optimized: {:?} total, {}ns per call", optimized_duration, optimized_avg_ns);
        
        // Optimized should be at least as fast as the best implementation
        assert!(optimized_duration <= debruijn_duration,
                "Optimized implementation should be at least as fast as DeBruijn");
    }
    
    // Test reverse scanning
    for (name, bb) in test_cases {
        println!("\n=== Bit Scan Reverse Performance: {} ===", name);
        
        // Benchmark hardware implementation
        #[cfg(all(target_arch = "x86_64", not(target_arch = "wasm32")))]
        {
            let start = Instant::now();
            for _ in 0..iterations {
                let _result = bit_scan_reverse_hardware(bb);
            }
            let hardware_duration = start.elapsed();
            let avg_ns = hardware_duration.as_nanos() / iterations;
            println!("  Hardware: {:?} total, {}ns per call", hardware_duration, avg_ns);
            
            assert!(avg_ns < 100, "Hardware reverse bitscan too slow: {}ns per call", avg_ns);
        }
        
        // Benchmark DeBruijn implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_reverse_debruijn(bb);
        }
        let debruijn_duration = start.elapsed();
        let avg_ns = debruijn_duration.as_nanos() / iterations;
        println!("  DeBruijn: {:?} total, {}ns per call", debruijn_duration, avg_ns);
        
        // Benchmark software implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_reverse_software(bb);
        }
        let software_duration = start.elapsed();
        let software_avg_ns = software_duration.as_nanos() / iterations;
        println!("  Software: {:?} total, {}ns per call", software_duration, software_avg_ns);
        
        // DeBruijn should be faster than software
        assert!(debruijn_duration <= software_duration,
                "DeBruijn reverse implementation should be faster than software");
        
        // Benchmark optimized implementation
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = bit_scan_optimized(bb, false);
        }
        let optimized_duration = start.elapsed();
        let optimized_avg_ns = optimized_duration.as_nanos() / iterations;
        println!("  Optimized: {:?} total, {}ns per call", optimized_duration, optimized_avg_ns);
        
        // Optimized should be at least as fast as the best implementation
        assert!(optimized_duration <= debruijn_duration,
                "Optimized reverse implementation should be at least as fast as DeBruijn");
    }
}

/// Performance benchmarks for utility functions
#[test]
fn test_utility_functions_performance() {
    let test_cases = [
        ("Empty", 0u128),
        ("Single bit", 1u128),
        ("Multiple bits", 0b1010101010101010u128),
        ("Dense", 0xFFFFFFFFFFFFFFFFu128),
        ("Sparse", 0x8000000000000000u128),
    ];
    
    let iterations = 1_000_000;
    
    for (name, bb) in test_cases {
        println!("\n=== Utility Functions Performance: {} ===", name);
        
        // Test utility function performance
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = is_single_bit(bb);
        }
        let single_bit_duration = start.elapsed();
        println!("  is_single_bit: {:?} total", single_bit_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = is_multiple_bits(bb);
        }
        let multiple_bits_duration = start.elapsed();
        println!("  is_multiple_bits: {:?} total", multiple_bits_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = is_empty(bb);
        }
        let empty_duration = start.elapsed();
        println!("  is_empty: {:?} total", empty_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = isolate_lsb(bb);
        }
        let isolate_lsb_duration = start.elapsed();
        println!("  isolate_lsb: {:?} total", isolate_lsb_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = isolate_msb(bb);
        }
        let isolate_msb_duration = start.elapsed();
        println!("  isolate_msb: {:?} total", isolate_msb_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = clear_lsb(bb);
        }
        let clear_lsb_duration = start.elapsed();
        println!("  clear_lsb: {:?} total", clear_lsb_duration);
        
        let start = Instant::now();
        for _ in 0..iterations {
            let _result = clear_msb(bb);
        }
        let clear_msb_duration = start.elapsed();
        println!("  clear_msb: {:?} total", clear_msb_duration);
        
        // Test bit position enumeration (only for small iterations to avoid timeout)
        let small_iterations = 10_000;
        let start = Instant::now();
        for _ in 0..small_iterations {
            let _result = get_all_bit_positions(bb);
        }
        let positions_duration = start.elapsed();
        println!("  get_all_bit_positions: {:?} total ({} iterations)", positions_duration, small_iterations);
        
        // Utility functions should be very fast (single instruction where possible)
        let max_expected_duration = Duration::from_millis(100); // 100ms max
        assert!(single_bit_duration < max_expected_duration,
                "is_single_bit too slow: {:?}", single_bit_duration);
        assert!(multiple_bits_duration < max_expected_duration,
                "is_multiple_bits too slow: {:?}", multiple_bits_duration);
        assert!(empty_duration < max_expected_duration,
                "is_empty too slow: {:?}", empty_duration);
        assert!(isolate_lsb_duration < max_expected_duration,
                "isolate_lsb too slow: {:?}", isolate_lsb_duration);
        assert!(isolate_msb_duration < max_expected_duration,
                "isolate_msb too slow: {:?}", isolate_msb_duration);
        assert!(clear_lsb_duration < max_expected_duration,
                "clear_lsb too slow: {:?}", clear_lsb_duration);
        assert!(clear_msb_duration < max_expected_duration,
                "clear_msb too slow: {:?}", clear_msb_duration);
    }
}

/// Performance regression test - ensure no significant performance degradation
#[test]
fn test_performance_regression() {
    let test_bitboard = 0x123456789ABCDEF0123456789ABCDEF0u128;
    let iterations = 100_000;
    
    // Test popcount performance regression
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = popcount(test_bitboard);
    }
    let popcount_duration = start.elapsed();
    let avg_ns = popcount_duration.as_nanos() / iterations;
    
    // Should be fast (less than 100ns per call for most implementations)
    assert!(avg_ns < 1000, "Popcount performance regression: {}ns per call", avg_ns);
    
    // Test bit scanning performance regression
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = bit_scan_forward(test_bitboard);
    }
    let bitscan_duration = start.elapsed();
    let avg_ns = bitscan_duration.as_nanos() / iterations;
    
    // Should be fast (less than 200ns per call for most implementations)
    assert!(avg_ns < 2000, "Bit scan performance regression: {}ns per call", avg_ns);
    
    println!("Performance regression test results:");
    println!("  Popcount: {}ns per call", popcount_duration.as_nanos() / iterations);
    println!("  Bit scan forward: {}ns per call", bitscan_duration.as_nanos() / iterations);
}

/// Platform-specific performance validation
#[test]
fn test_platform_specific_performance() {
    let capabilities = get_platform_capabilities();
    let test_bitboard = 0x123456789ABCDEF0u128;
    let iterations = 100_000;
    
    println!("\n=== Platform-Specific Performance Validation ===");
    println!("Platform: {:?}", capabilities.architecture);
    println!("WASM: {}", capabilities.is_wasm);
    println!("POPCNT: {}", capabilities.has_popcnt);
    println!("BMI1: {}", capabilities.has_bmi1);
    println!("BMI2: {}", capabilities.has_bmi2);
    
    // Test popcount performance
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = popcount(test_bitboard);
    }
    let popcount_duration = start.elapsed();
    let avg_ns = popcount_duration.as_nanos() / iterations;
    println!("Popcount: {}ns per call", avg_ns);
    
    // Test bit scanning performance
    let start = Instant::now();
    for _ in 0..iterations {
        let _result = bit_scan_forward(test_bitboard);
    }
    let bitscan_duration = start.elapsed();
    let avg_ns = bitscan_duration.as_nanos() / iterations;
    println!("Bit scan forward: {}ns per call", avg_ns);
    
    // Platform-specific performance expectations
    #[cfg(target_arch = "wasm32")]
    {
        // WASM should use SWAR/DeBruijn implementations
        // Performance should be reasonable but not hardware-accelerated
        assert!(popcount_duration.as_nanos() / iterations < 2000,
                "WASM popcount too slow: {}ns per call", avg_ns);
        assert!(bitscan_duration.as_nanos() / iterations < 3000,
                "WASM bitscan too slow: {}ns per call", avg_ns);
    }
    
    #[cfg(all(target_arch = "x86_64", not(target_arch = "wasm32")))]
    {
        // x86_64 should potentially use hardware acceleration
        if capabilities.has_popcnt {
            assert!(popcount_duration.as_nanos() / iterations < 500,
                    "Hardware popcount too slow: {}ns per call", avg_ns);
        }
        if capabilities.has_bmi1 {
            assert!(bitscan_duration.as_nanos() / iterations < 1000,
                    "Hardware bitscan too slow: {}ns per call", avg_ns);
        }
    }
    
    #[cfg(all(target_arch = "aarch64", not(target_arch = "wasm32")))]
    {
        // ARM should use native instructions where available
        assert!(popcount_duration.as_nanos() / iterations < 1000,
                "ARM popcount too slow: {}ns per call", avg_ns);
        assert!(bitscan_duration.as_nanos() / iterations < 1500,
                "ARM bitscan too slow: {}ns per call", avg_ns);
    }
}

/// Memory usage validation
#[test]
fn test_memory_usage_validation() {
    use std::mem;
    
    println!("\n=== Memory Usage Validation ===");
    
    // Test that lookup tables are reasonably sized
    let popcount_impl = get_best_popcount_impl();
    let bitscan_impl = get_best_bitscan_impl();
    
    println!("Popcount implementation: {:?}", popcount_impl);
    println!("Bitscan implementation: {:?}", bitscan_impl);
    
    // Test that we don't have excessive memory usage
    // This is more of a compile-time check, but we can verify the structures are reasonable
    let capabilities_size = mem::size_of_val(&detect_platform_capabilities());
    println!("PlatformCapabilities size: {} bytes", capabilities_size);
    
    // Should be small (under 100 bytes)
    assert!(capabilities_size < 100, "PlatformCapabilities too large: {} bytes", capabilities_size);
    
    // Test that we don't have memory leaks during operation
    let test_bitboard = 0x123456789ABCDEF0u128;
    
    // Run many iterations to check for memory issues
    for _ in 0..100_000 {
        let _result1 = popcount(test_bitboard);
        let _result2 = bit_scan_forward(test_bitboard);
        let _result3 = bit_scan_reverse(test_bitboard);
        let _result4 = get_all_bit_positions(test_bitboard);
        let _result5 = isolate_lsb(test_bitboard);
        let _result6 = isolate_msb(test_bitboard);
        let _result7 = clear_lsb(test_bitboard);
        let _result8 = clear_msb(test_bitboard);
    }
    
    // If we get here without running out of memory, the test passes
    println!("Memory usage validation passed - no leaks detected");
}

/// Stress test for performance under load
#[test]
fn test_performance_under_load() {
    let test_cases = [
        0u128, 1u128, 0xFFu128, 0x1000u128,
        0x8000000000000000u128, 0xFFFFFFFFFFFFFFFFu128,
        0x5555555555555555u128, 0xAAAAAAAAAAAAAAAAu128,
        0x123456789ABCDEF0u128, 0xFEDCBA9876543210u128,
    ];
    
    let iterations = 50_000;
    
    println!("\n=== Performance Under Load ===");
    
    let start = Instant::now();
    for bb in test_cases.iter().cycle().take(iterations) {
        let _result1 = popcount(*bb);
        let _result2 = bit_scan_forward(*bb);
        let _result3 = bit_scan_reverse(*bb);
        let _result4 = popcount_optimized(*bb);
        let _result5 = bit_scan_optimized(*bb, true);
        let _result6 = bit_scan_optimized(*bb, false);
        let _result7 = is_single_bit(*bb);
        let _result8 = is_multiple_bits(*bb);
        let _result9 = is_empty(*bb);
    }
    let total_duration = start.elapsed();
    
    let avg_ns = total_duration.as_nanos() / (iterations * 9); // 9 operations per iteration
    println!("Average time per operation: {}ns", avg_ns);
    
    // Should complete in reasonable time (less than 10ms total)
    assert!(total_duration < Duration::from_millis(10),
            "Performance under load too slow: {:?}", total_duration);
    
    // Individual operations should be fast
    assert!(avg_ns < 500, "Individual operations too slow: {}ns", avg_ns);
}
